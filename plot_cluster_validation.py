#!/usr/bin/env python3
"""
Plot cluster validation metrics (elbow and silhouette) from parallel clustering results.

This script reads the k*_results.txt files generated by the parallel voxel clustering
workflow and creates clean elbow and silhouette plots for cluster validation.

Usage:
    python plot_cluster_validation.py --results_dir /path/to/results --output_dir /path/to/plots
    python plot_cluster_validation.py --results_dir derivatives/voxel_clustering
"""

import argparse
import os
import os.path as op
import re
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


def get_parser():
    """Command line argument parser"""
    p = argparse.ArgumentParser(description="Plot cluster validation metrics")
    p.add_argument(
        "--results_dir",
        required=True,
        help="Directory containing k*_results.txt files",
    )
    p.add_argument(
        "--output_dir",
        help="Directory to save plots",
    )
    p.add_argument(
        "--k_min",
        type=int,
        default=2,
        help="Minimum k value to plot",
    )
    p.add_argument(
        "--k_max",
        type=int,
        default=10,
        help="Maximum k value to plot",
    )
    p.add_argument(
        "--figsize",
        nargs=2,
        type=float,
        default=[12, 5],
        help="Figure size (width height)",
    )
    p.add_argument(
        "--dpi",
        type=int,
        default=300,
        help="Figure DPI for saved plots",
    )
    return p


def parse_results_file(filepath):
    """Parse a k*_results.txt file to extract metrics"""
    metrics = {}

    try:
        with open(filepath, "r") as f:
            content = f.read()

        # Extract k value from filename
        k_match = re.search(r"k(\d+)_results\.txt", op.basename(filepath))
        if k_match:
            k_value = int(k_match.group(1))
            metrics["k"] = k_value

        # Extract method
        method_match = re.search(r"Method:\s*(\w+)", content)
        if method_match:
            metrics["method"] = method_match.group(1)

        # Extract silhouette score
        sil_match = re.search(r"Silhouette score:\s*([\d\.-]+)", content)
        if sil_match:
            metrics["silhouette"] = float(sil_match.group(1))

        # Extract gap statistic
        gap_match = re.search(r"gap_statistic:\s*([\d\.-]+)", content)
        if gap_match:
            metrics["gap_statistic"] = float(gap_match.group(1))

        # Extract gap standard error
        gap_std_match = re.search(r"gap_std:\s*([\d\.-]+)", content)
        if gap_std_match:
            metrics["gap_std"] = float(gap_std_match.group(1))

        # Extract group sizes
        groups_match = re.search(r"Participants per group:\s*\[(.*?)\]", content)
        if groups_match:
            group_sizes = [int(x.strip()) for x in groups_match.group(1).split()]
            metrics["group_sizes"] = group_sizes

    except Exception as e:
        print(f"Warning: Could not parse {filepath}: {e}")

    return metrics


def collect_all_results(results_dir, k_min=2, k_max=10):
    """Collect results from all k*_results.txt files or DataFrame CSV"""
    print(f"Collecting results from: {results_dir}")

    # First try to load from validation DataFrame CSV
    csv_file = op.join(results_dir, "cluster_validation_metrics.csv")
    if op.exists(csv_file):
        print(f"Found validation DataFrame: {csv_file}")
        try:
            df = pd.read_csv(csv_file)
            # Filter by k range
            df = df[(df["k"] >= k_min) & (df["k"] <= k_max)]

            # Convert to the expected format
            all_metrics = []
            for _, row in df.iterrows():
                metrics = {
                    "k": int(row["k"]),
                    "method": "hierarchical",
                    "silhouette": row.get("silhouette_score", np.nan),
                    "gap_statistic": row.get("gap_statistic", np.nan),
                    "gap_std": row.get("gap_std", np.nan),
                    "vrc": row.get("vrc", np.nan),
                    "cluster_separation": row.get("cluster_separation", np.nan),
                    "hierarchy_index": row.get("hierarchy_index", np.nan),
                }
                all_metrics.append(metrics)

                sil_score = metrics.get("silhouette", "N/A")
                gap_val = metrics.get("gap_statistic", "N/A")
                print(f"  k={metrics['k']}: silhouette={sil_score}, gap={gap_val}")

            print(f"Loaded {len(all_metrics)} results from DataFrame")
            return sorted(all_metrics, key=lambda x: x["k"])

        except Exception as e:
            print(f"Error reading DataFrame CSV: {e}")
            print("Falling back to individual k*_results.txt files...")

    # Fallback to original method with individual files
    # Find all k*_results.txt files
    pattern = op.join(results_dir, "k*_results.txt")
    result_files = glob.glob(pattern)

    if not result_files:
        raise FileNotFoundError(
            f"No k*_results.txt files or validation CSV found in {results_dir}"
        )

    print(f"Found {len(result_files)} result files")

    all_metrics = []
    for filepath in result_files:
        metrics = parse_results_file(filepath)
        if metrics and "k" in metrics:
            # Filter by k range
            if k_min <= metrics["k"] <= k_max:
                all_metrics.append(metrics)
                sil_score = metrics.get("silhouette", "N/A")
                gap_val = metrics.get("gap_statistic", "N/A")
                print(f"  k={metrics['k']}: silhouette={sil_score}, gap={gap_val}")

    # Sort by k value
    all_metrics.sort(key=lambda x: x["k"])
    return all_metrics


def plot_validation_metrics(all_metrics, output_dir, figsize=(15, 10), dpi=300):
    """Create comprehensive validation plots including silhouette, gap statistic, VRC, cluster separation, and hierarchy index"""
    if not all_metrics:
        raise ValueError("No valid metrics found to plot")

    print("Creating validation plots...")

    # Extract data
    k_values = [m["k"] for m in all_metrics]
    silhouette_scores = [m.get("silhouette", np.nan) for m in all_metrics]

    # Check if we have silhouette scores
    has_silhouette = not all(np.isnan(silhouette_scores))

    # Create figure with 5 subplots (2 rows, 3 columns)
    fig = plt.figure(figsize=figsize)
    gs = plt.GridSpec(2, 3, figure=fig)
    
    # Create axes for each plot
    ax_sil = fig.add_subplot(gs[0, 0])  # Silhouette score
    ax_gap = fig.add_subplot(gs[0, 1])  # Gap statistic
    ax_vrc = fig.add_subplot(gs[0, 2])  # VRC
    ax_sep = fig.add_subplot(gs[1, 0])  # Cluster separation
    ax_hi = fig.add_subplot(gs[1, 1])   # Hierarchy index
    ax_group = fig.add_subplot(gs[1, 2]) # Group sizes
    
    axes = [ax_sil, ax_gap, ax_vrc, ax_sep, ax_hi, ax_group]

    # Plot 1: Silhouette Analysis
    if has_silhouette:
        # Remove NaN values for plotting
        valid_indices = ~np.isnan(silhouette_scores)
        valid_k = np.array(k_values)[valid_indices]
        valid_sil = np.array(silhouette_scores)[valid_indices]

        axes[0].plot(valid_k, valid_sil, "o-", linewidth=2, markersize=6, color="blue")
        axes[0].set_xlabel("Number of Clusters (k)")
        axes[0].set_ylabel("Silhouette Score")
        axes[0].set_title("Silhouette Analysis")
        axes[0].grid(True, alpha=0.3)
        axes[0].set_xticks(valid_k)

        # Highlight best k
        if len(valid_sil) > 0:
            best_idx = np.argmax(valid_sil)
            best_k = valid_k[best_idx]
            best_score = valid_sil[best_idx]
            axes[0].axvline(best_k, color="red", linestyle="--", alpha=0.7)

            # Position annotation based on plot area
            y_range = axes[0].get_ylim()
            y_offset = (y_range[1] - y_range[0]) * 0.05  # 5% of y-range

            axes[0].annotate(
                f"Best k={best_k}\nScore={best_score:.3f}",
                xy=(best_k, best_score),
                xytext=(best_k + 0.5, best_score + y_offset),
                arrowprops=dict(arrowstyle="->", color="red"),
                bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
                fontsize=10,
            )

    # Plot 2: Gap Statistic
    gap_values = [m.get("gap_statistic", np.nan) for m in all_metrics]
    gap_stds = [m.get("gap_std", np.nan) for m in all_metrics]
    has_gap = not all(np.isnan(gap_values))

    if has_gap:
        valid_indices = ~np.isnan(gap_values)
        valid_k = np.array(k_values)[valid_indices]
        valid_gap = np.array(gap_values)[valid_indices]
        valid_gap_std = np.array(gap_stds)[valid_indices]

        axes[1].errorbar(
            valid_k,
            valid_gap,
            yerr=valid_gap_std,
            fmt="o-",
            linewidth=2,
            markersize=6,
            color="green",
            capsize=5,
        )
        axes[1].set_xlabel("Number of Clusters (k)")
        axes[1].set_ylabel("Gap Statistic")
        axes[1].set_title("Gap Statistic Analysis")
        axes[1].grid(True, alpha=0.3)
        axes[1].set_xticks(valid_k)

    # Plot 3: Variance Ratio Criterion (VRC)
    vrc_values = [m.get("vrc", np.nan) for m in all_metrics]
    has_vrc = not all(np.isnan(vrc_values))

    if has_vrc:
        valid_indices = ~np.isnan(vrc_values)
        valid_k = np.array(k_values)[valid_indices]
        valid_vrc = np.array(vrc_values)[valid_indices]

        axes[2].plot(
            valid_k,
            valid_vrc,
            "o-",
            linewidth=2,
            markersize=6,
            color="purple",
        )
        axes[2].set_xlabel("Number of Clusters (k)")
        axes[2].set_ylabel("Variance Ratio Criterion")
        axes[2].set_title("VRC Analysis")
        axes[2].grid(True, alpha=0.3)
        axes[2].set_xticks(valid_k)

    # Plot 4: Cluster Separation
    sep_values = [m.get("cluster_separation", np.nan) for m in all_metrics]
    has_sep = not all(np.isnan(sep_values))

    if has_sep:
        valid_indices = ~np.isnan(sep_values)
        valid_k = np.array(k_values)[valid_indices]
        valid_sep = np.array(sep_values)[valid_indices]

        axes[3].plot(
            valid_k,
            valid_sep,
            "o-",
            linewidth=2,
            markersize=6,
            color="orange",
        )
        axes[3].set_xlabel("Number of Clusters (k)")
        axes[3].set_ylabel("Cluster Separation")
        axes[3].set_title("Cluster Separation Analysis")
        axes[3].grid(True, alpha=0.3)
        axes[3].set_xticks(valid_k)

    # Plot 5: Hierarchy Index
    hi_values = [m.get("hierarchy_index", np.nan) for m in all_metrics]
    has_hi = not all(np.isnan(hi_values))

    if has_hi:
        valid_indices = ~np.isnan(hi_values)
        valid_k = np.array(k_values)[valid_indices]
        valid_hi = np.array(hi_values)[valid_indices]

        axes[4].plot(
            valid_k,
            valid_hi,
            "o-",
            linewidth=2,
            markersize=6,
            color="brown",
        )
        axes[4].set_xlabel("Number of Clusters (k)")
        axes[4].set_ylabel("Hierarchy Index")
        axes[4].set_title("Hierarchy Index Analysis")
        axes[4].grid(True, alpha=0.3)
        axes[4].set_xticks(valid_k)

    # Plot 6: Group Sizes
    axes[5].set_title("Group Sizes by k")
    axes[5].set_xlabel("Number of Clusters (k)")
    axes[5].set_ylabel("Participants per Group")

    # Create grouped bar chart for group sizes
    width = 0.8 / max(k_values) if k_values else 0.1
    for i, metrics in enumerate(all_metrics):
        k = metrics["k"]
        group_sizes = metrics.get("group_sizes", [])
        if group_sizes:
            positions = [
                k + j * width - width * len(group_sizes) / 2
                for j in range(len(group_sizes))
            ]
            axes[5].bar(
                positions,
                group_sizes,
                width=width,
                alpha=0.7,
                label=f"k={k}" if len(all_metrics) <= 5 else None,
            )

    if len(all_metrics) <= 5:
        axes[5].legend()
    axes[5].grid(True, alpha=0.3)

    plt.tight_layout()

    # Save plot
    os.makedirs(output_dir, exist_ok=True)
    output_file = op.join(output_dir, "cluster_validation_summary.png")
    plt.savefig(output_file, dpi=dpi, bbox_inches="tight")
    print(f"Validation plot saved to: {output_file}")

    plt.show()

    return output_file


def main():
    """Main function"""
    args = get_parser().parse_args()

    # Set default output directory
    if args.output_dir is None:
        default_dir = op.join("derivatives", "hierarchical_clustering", "figures")
        args.output_dir = default_dir

    print("Cluster Validation Plotting Tool")
    print("=" * 40)
    print(f"Results directory: {args.results_dir}")
    print(f"Output directory: {args.output_dir}")
    print(f"K range: {args.k_min} to {args.k_max}")

    try:
        # Collect all results
        all_metrics = collect_all_results(args.results_dir, args.k_min, args.k_max)

        if not all_metrics:
            print("No valid results found!")
            return 1

        # Create plots
        plot_validation_metrics(
            all_metrics, args.output_dir, figsize=args.figsize, dpi=args.dpi
        )

        print("\nSUCCESS!")
        print(f"Processed {len(all_metrics)} cluster solutions")
        print(f"Plots saved to: {args.output_dir}")

        return 0

    except Exception as e:
        print(f"ERROR: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
